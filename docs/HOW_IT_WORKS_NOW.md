# How The System Works Now (with issues identified)

## Current Flow

### 1. **HomePage ‚Üí Workspace Navigation**
```
User enters prompt: "Build a cat classifier"
  ‚Üì
Creates BuildSession:
  {
    goalPrompt: "Build a cat classifier",
    datasetLinks: [...],
    status: "building"
  }
  ‚Üì
Navigate to /workspace
  ‚Üì
RealBackendLoader mounts
```

### 2. **WebSocket Connection (Automatic)**
```
AppShell useEffect runs:
  ‚Üì
Calls: projectStore.connect({ projectId: "demo-project" })
  ‚Üì
WebSocket connects to: ws://localhost:8000/ws/projects/demo-project
  ‚Üì
Backend sends initial events:
  - HELLO (connection established)
  - STAGE_STATUS (current stage: PARSE_INTENT, status: PENDING)
```

### 3. **Prompt Review Screen**
```
RealBackendLoader checks:
  - pipelineStarted? NO
  - hasPipelineEvents? NO (only HELLO & STAGE_STATUS)
  ‚Üì
Shows Prompt Review Screen:
  ‚ú® Ready to Start
  üìù Your Goal: "Build a cat classifier"
  üöÄ [Start Pipeline] button
```

### 4. **User Clicks "Start Pipeline"**
```
handleStart() called:
  ‚Üì
Sets: pipelineStarted = true
  ‚Üì
Calls: startPipeline(session.goalPrompt)
  ‚Üì
Makes HTTP Request:
  POST /api/projects/demo-project/parse
  Body: {"prompt": "Build a cat classifier"}
```

### 5. **Backend Processes Parse Intent**
```
Backend receives /parse request:
  ‚Üì
Creates PromptParserAgent
  ‚Üì
Calls LLM (Gemini/OpenRouter):
  - Analyzes prompt
  - Extracts: task_type, target, dataset_hint, constraints
  - Takes 2-5 seconds
  ‚Üì
Returns parsed payload:
  {
    "task_type": "classification",
    "target": "cat vs dog",
    "dataset_hint": "cat and dog images",
    "constraints": {}
  }
  ‚Üì
Publishes WebSocket Event:
  EventType.PROMPT_PARSED (payload: parsed data)
  ‚Üì
Updates stage status:
  PARSE_INTENT ‚Üí COMPLETED
  DATA_SOURCE ‚Üí WAITING_CONFIRMATION
```

### 6. **Frontend Receives Events**
```
WebSocket receives events:
  ‚Üì
Events stored in projectStore
  ‚Üì
useBackendPipeline hook updates:
  - events array grows
  - currentStage changes to DATA_SOURCE
  - stages[DATA_SOURCE].status = WAITING_CONFIRMATION
  ‚Üì
RealBackendLoader re-renders:
  - Shows event stream
  - Shows "Confirm & Continue" button
```

### 7. **User Clicks "Confirm & Continue"**
```
confirmStage() called:
  ‚Üì
Makes HTTP Request:
  POST /api/projects/demo-project/confirm
  ‚Üì
Backend conductor.confirm():
  ‚ùå PROBLEM: Doesn't check if stage is WAITING_CONFIRMATION
  ‚úÖ Marks current stage COMPLETED
  ‚úÖ Advances to next stage (DATA_CLEAN)
  ‚úÖ Sets next stage to IN_PROGRESS
  ‚Üì
Publishes events via WebSocket
  ‚Üì
Frontend updates and cycle repeats
```

---

## üêõ **IDENTIFIED ISSUES**

### Issue 1: Confirm Can Be Spammed
**Problem**: `conductor.confirm()` doesn't validate that the current stage is `WAITING_CONFIRMATION`

**Current Code**:
```python
async def confirm(self, project_id: str) -> Dict[str, Any]:
    # ‚ùå No check if stages[current_stage]["status"] == WAITING_CONFIRMATION
    stages[current_stage]["status"] = StageStatus.COMPLETED
    # Advances to next stage blindly
```

**Result**: User can spam "Confirm" button and skip through ALL stages instantly without any actual work happening.

**Fix Needed**: Add validation:
```python
async def confirm(self, project_id: str) -> Dict[str, Any]:
    current_stage: StageID = state["current_stage"]
    
    # ‚úÖ Add this check
    if stages[current_stage]["status"] != StageStatus.WAITING_CONFIRMATION:
        raise HTTPException(
            status_code=400, 
            detail=f"Stage {current_stage.value} is not waiting for confirmation"
        )
    
    # Then proceed with confirmation logic
```

---

### Issue 2: Stages Don't Do Actual Work
**Problem**: Most stages just transition immediately without calling agents or doing real work.

**Current Behavior**:
- ‚úÖ **PARSE_INTENT**: Actually calls PromptParserAgent (LLM processes)
- ‚ùå **DATA_SOURCE**: No agent called, just waits for confirm
- ‚ùå **DATA_CLEAN**: No agent called, just waits for confirm
- ‚ùå **FEATURE_ENG**: No agent called, just waits for confirm
- ‚ùå **MODEL_SELECT**: Has `ModelSelectorAgent` but not wired to /confirm
- ‚ùå **TRAIN**: No agent called, just waits for confirm
- ‚ùå **EVALUATE**: No agent called, just waits for confirm
- ‚ùå **EXPORT**: No agent called, just waits for confirm

**What Should Happen**:
Each stage should trigger actual work BEFORE going to WAITING_CONFIRMATION:

```python
# Example for DATA_CLEAN stage:
async def confirm(self, project_id: str):
    next_stage = advance_to_next()
    
    # When advancing to DATA_CLEAN, trigger agent
    if next_stage == StageID.DATA_CLEAN:
        # Call DataCleanAgent in background
        await trigger_data_cleaning(project_id)
        # Agent will emit progress events
        # Agent will set status to WAITING_CONFIRMATION when done
```

---

### Issue 3: Parse Might Not Be Actually Running
**Question**: "I don't know if it's actually parsing the text"

**How to Check**:
1. **Look at backend terminal logs** - You should see:
   ```
   ============================================================
   [PARSE INTENT] Starting for project: demo-project
   [PARSE INTENT] Prompt: Build a cat classifier...
   ============================================================
   [PromptParser] Using LangChain LLM...
   [PromptParser] Invoking LLM chain...
   [PromptParser] ‚úÖ LLM response received in 3.2s
   ============================================================
   [PARSE INTENT] ‚úÖ COMPLETED
   ============================================================
   ```

2. **Check frontend events** - Look for `PROMPT_PARSED` event with actual parsed data

3. **Watch for delay** - If parse is actually working, there should be a 2-5 second delay after clicking "Start Pipeline"

**If you DON'T see these logs**:
- The `/parse` endpoint might not be getting called
- Check browser Network tab for POST request to `/api/projects/demo-project/parse`
- Check for errors in browser console

---

## üéØ **What Each Stage SHOULD Do**

### PARSE_INTENT ‚úÖ (Working)
```
User clicks "Start Pipeline"
  ‚Üí POST /api/projects/demo-project/parse
  ‚Üí PromptParserAgent processes with LLM
  ‚Üí Returns: {task_type, target, dataset_hint, constraints}
  ‚Üí Sets stage to COMPLETED
  ‚Üí Advances to DATA_SOURCE
```

### DATA_SOURCE ‚è≥ (Needs Work)
```
When DATA_SOURCE becomes IN_PROGRESS:
  ‚Üí Show file upload UI OR
  ‚Üí Use session.datasetLinks automatically
  ‚Üí User uploads file OR confirms dataset
  ‚Üí POST /api/projects/demo-project/upload
  ‚Üí DataIngestionAgent processes file
  ‚Üí Emits: DATASET_LOADED event
  ‚Üí Sets stage to WAITING_CONFIRMATION
  ‚Üí User confirms ‚Üí Advances to DATA_CLEAN
```

### DATA_CLEAN ‚è≥ (Needs Work)
```
When DATA_CLEAN becomes IN_PROGRESS:
  ‚Üí DataCleanAgent automatically runs
  ‚Üí Analyzes dataset for:
    - Missing values
    - Outliers
    - Inconsistencies
  ‚Üí Emits: DATA_PROFILE events (progress)
  ‚Üí When done, emits: DATA_CLEANED event
  ‚Üí Sets stage to WAITING_CONFIRMATION
  ‚Üí User reviews cleaning results
  ‚Üí User confirms ‚Üí Advances to FEATURE_ENG
```

### FEATURE_ENG ‚è≥ (Needs Work)
```
When FEATURE_ENG becomes IN_PROGRESS:
  ‚Üí FeatureEngineeringAgent runs
  ‚Üí Suggests feature transformations
  ‚Üí Applies: encoding, scaling, etc.
  ‚Üí Emits: FEATURES_READY event
  ‚Üí Sets stage to WAITING_CONFIRMATION
  ‚Üí User confirms ‚Üí Advances to MODEL_SELECT
```

### MODEL_SELECT ‚è≥ (Needs Work)
```
When MODEL_SELECT becomes IN_PROGRESS:
  ‚Üí ModelSelectorAgent runs
  ‚Üí Based on task_type, suggests models
  ‚Üí Emits: MODEL_CANDIDATES event
  ‚Üí Sets stage to WAITING_CONFIRMATION
  ‚Üí User selects model
  ‚Üí User confirms ‚Üí Advances to TRAIN
```

### TRAIN ‚è≥ (Needs Work)
```
When TRAIN becomes IN_PROGRESS:
  ‚Üí TrainingAgent starts training
  ‚Üí Emits: TRAIN_PROGRESS events (epoch updates)
  ‚Üí Shows: loss, accuracy, etc.
  ‚Üí When done, emits: TRAIN_COMPLETED
  ‚Üí Sets stage to WAITING_CONFIRMATION
  ‚Üí User confirms ‚Üí Advances to EVALUATE
```

### EVALUATE ‚è≥ (Needs Work)
```
When EVALUATE becomes IN_PROGRESS:
  ‚Üí EvaluationAgent runs
  ‚Üí Calculates metrics on test set
  ‚Üí Emits: EVAL_METRICS event
  ‚Üí Shows: accuracy, precision, recall, etc.
  ‚Üí Sets stage to WAITING_CONFIRMATION
  ‚Üí User confirms ‚Üí Advances to EXPORT
```

### EXPORT ‚è≥ (Needs Work)
```
When EXPORT becomes IN_PROGRESS:
  ‚Üí ExportAgent runs
  ‚Üí Generates: model file, notebook, API spec
  ‚Üí Emits: EXPORT_READY event
  ‚Üí Sets stage to COMPLETED
  ‚Üí Pipeline done!
```

---

## üîß **Immediate Fixes Needed**

### Priority 1: Fix Confirm Spam Issue
**File**: `backend/app/orchestrator/conductor.py`
**Add validation** to `confirm()` method

### Priority 2: Verify Parse is Actually Running
**Check**:
1. Backend terminal logs
2. Browser Network tab
3. Frontend console logs

### Priority 3: Wire Up Remaining Agents
**Each stage needs**:
1. Agent trigger when stage becomes IN_PROGRESS
2. Agent emits progress events
3. Agent sets WAITING_CONFIRMATION when done
4. Confirm button only enabled when WAITING_CONFIRMATION

---

## üìä **Current vs. Desired State**

| Stage | Current Behavior | Desired Behavior |
|-------|-----------------|------------------|
| PARSE_INTENT | ‚úÖ Calls LLM, parses prompt | ‚úÖ Working correctly |
| DATA_SOURCE | ‚ùå Just waits for confirm | Should upload/load dataset |
| DATA_CLEAN | ‚ùå Just waits for confirm | Should analyze & clean data |
| FEATURE_ENG | ‚ùå Just waits for confirm | Should engineer features |
| MODEL_SELECT | ‚ùå Just waits for confirm | Should suggest models |
| TRAIN | ‚ùå Just waits for confirm | Should actually train model |
| EVALUATE | ‚ùå Just waits for confirm | Should evaluate metrics |
| EXPORT | ‚ùå Just waits for confirm | Should export artifacts |

---

## üé¨ **What You Should See (Ideal Flow)**

1. Click "Start Pipeline" ‚Üí **2-5 sec delay** ‚Üí PROMPT_PARSED event
2. Click "Confirm" ‚Üí **DATA_SOURCE waits for upload**
3. Upload file ‚Üí **Processing** ‚Üí DATA_LOADED event
4. Click "Confirm" ‚Üí **DATA_CLEAN runs** ‚Üí Progress bars ‚Üí CLEANED event
5. Click "Confirm" ‚Üí **FEATURE_ENG runs** ‚Üí Features engineered
6. Click "Confirm" ‚Üí **MODEL_SELECT suggests** ‚Üí Pick model
7. Click "Confirm" ‚Üí **TRAIN shows progress** ‚Üí Loss/accuracy updates
8. Click "Confirm" ‚Üí **EVALUATE shows metrics** ‚Üí F1, precision, recall
9. Click "Confirm" ‚Üí **EXPORT generates** ‚Üí Notebook, API ready

**vs. What You See Now:**
Click confirm 8 times instantly ‚Üí All stages COMPLETED ‚Üí No actual work done

---

## Want me to fix these issues?

I can:
1. ‚úÖ Fix confirm validation (prevent spam)
2. ‚úÖ Add proper stage-to-agent wiring
3. ‚úÖ Make each stage do real work
4. ‚úÖ Add proper WAITING_CONFIRMATION logic

Let me know!
